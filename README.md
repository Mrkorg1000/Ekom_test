## Задача
Сделать простой сервер, который принимает изображение и отправляет его в бесплатный сервис модерации, чтобы понять — есть ли на нём нежелательный контент.

### Что нужно сделать: 

Написать backend-приложение на Python (лучше FastAPI, можно Flask)

Создать эндпоинт: POST /moderate

Принимает изображение (`.jpg`, `.png`)

Отправляет его в [DeepAI NSFW API](`https://deepai.org/machine-learning-model/nsfw-detector`)

### Возвращает результат:

{"status": "OK"} — если безопасно

{"status": "REJECTED", "reason": "NSFW content"} — если найден неприемлемый контент

Технические детали: API DeepAI: бесплатный, после регистрации даётся ключ

Условия:

Если nsfw_score > 0.7 → REJECTED

Иначе → OK


### Запуск приложения:

Для локального поднятия проекта необходимо скачать проект,
установить зависимости из файла `requirements.txt` и запускаем
приложение командой `uvicorn app.main:app --reload`
